name: Nightly Load Test

on:
  schedule:
    # Run at 2 AM UTC every day
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual triggering
    inputs:
      test_scenario:
        description: 'Test scenario to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - api_load
          - peak_load
          - upload_stress
          - tenant_isolation
      duration:
        description: 'Test duration override'
        required: false
        default: '5m'

env:
  API_BASE_URL: ${{ secrets.STAGING_API_URL }}
  AUTH_TOKEN: ${{ secrets.LOAD_TEST_TOKEN }}

jobs:
  load-test:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    strategy:
      matrix:
        scenario: 
          - api_load
          - peak_load
          - upload_stress
          - tenant_isolation
      fail-fast: false
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup k6
        uses: k6-io/action@v0.3.1
        with:
          version: v0.47.0
      
      - name: Warm up API
        run: |
          echo "Warming up API endpoints..."
          curl -f "$API_BASE_URL/health" || exit 1
          curl -f -H "Authorization: Bearer $AUTH_TOKEN" "$API_BASE_URL/api/v1/ping" || exit 1
      
      - name: Run load test - ${{ matrix.scenario }}
        if: ${{ github.event.inputs.test_scenario == 'all' || github.event.inputs.test_scenario == matrix.scenario || github.event.inputs.test_scenario == '' }}
        run: |
          k6 run \
            --env K6_SCENARIO=${{ matrix.scenario }} \
            --env API_BASE_URL=$API_BASE_URL \
            --env AUTH_TOKEN=$AUTH_TOKEN \
            --out json=results-${{ matrix.scenario }}.json \
            --out cloud \
            load-tests/k6-suite.js
        env:
          K6_CLOUD_TOKEN: ${{ secrets.K6_CLOUD_TOKEN }}
      
      - name: Parse results
        if: always()
        run: |
          if [ -f "results-${{ matrix.scenario }}.json" ]; then
            echo "## Load Test Results - ${{ matrix.scenario }}" >> $GITHUB_STEP_SUMMARY
            
            # Extract key metrics
            p95_latency=$(jq -r '.metrics.http_req_duration.values.p95' results-${{ matrix.scenario }}.json)
            error_rate=$(jq -r '.metrics.http_req_failed.values.rate' results-${{ matrix.scenario }}.json)
            rps=$(jq -r '.metrics.http_reqs.values.rate' results-${{ matrix.scenario }}.json)
            
            echo "- **P95 Latency**: ${p95_latency}ms" >> $GITHUB_STEP_SUMMARY
            echo "- **Error Rate**: $(echo "$error_rate * 100" | bc -l)%" >> $GITHUB_STEP_SUMMARY
            echo "- **Requests/sec**: $rps" >> $GITHUB_STEP_SUMMARY
            
            # Check SLA compliance
            if (( $(echo "$p95_latency > 500" | bc -l) )); then
              echo "❌ **SLA VIOLATION**: P95 latency exceeded 500ms threshold" >> $GITHUB_STEP_SUMMARY
              echo "sla_violation=true" >> $GITHUB_ENV
            fi
            
            if (( $(echo "$error_rate > 0.01" | bc -l) )); then
              echo "❌ **SLA VIOLATION**: Error rate exceeded 1% threshold" >> $GITHUB_STEP_SUMMARY
              echo "sla_violation=true" >> $GITHUB_ENV
            fi
          fi
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results-${{ matrix.scenario }}
          path: results-${{ matrix.scenario }}.json
          retention-days: 30
      
      - name: Notify on SLA violation
        if: env.sla_violation == 'true'
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          channel: '#alerts'
          text: |
            🚨 **Load Test SLA Violation** 🚨
            Scenario: ${{ matrix.scenario }}
            P95 Latency: ${{ env.p95_latency }}ms (limit: 500ms)
            Error Rate: ${{ env.error_rate }}% (limit: 1%)
            
            View details: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  performance-regression:
    runs-on: ubuntu-latest
    needs: load-test
    if: always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download test results
        uses: actions/download-artifact@v4
        with:
          path: ./results
      
      - name: Compare with baseline
        run: |
          echo "## Performance Regression Analysis" >> $GITHUB_STEP_SUMMARY
          
          # Compare against baseline (stored in repo)
          if [ -f "load-tests/baseline-metrics.json" ]; then
            for scenario in api_load peak_load upload_stress tenant_isolation; do
              if [ -f "results/load-test-results-$scenario/results-$scenario.json" ]; then
                current_p95=$(jq -r '.metrics.http_req_duration.values.p95' results/load-test-results-$scenario/results-$scenario.json)
                baseline_p95=$(jq -r ".[\"$scenario\"].p95_latency" load-tests/baseline-metrics.json)
                
                regression_pct=$(echo "scale=2; ($current_p95 - $baseline_p95) / $baseline_p95 * 100" | bc -l)
                
                echo "### $scenario" >> $GITHUB_STEP_SUMMARY
                echo "- Current P95: ${current_p95}ms" >> $GITHUB_STEP_SUMMARY
                echo "- Baseline P95: ${baseline_p95}ms" >> $GITHUB_STEP_SUMMARY
                echo "- Change: ${regression_pct}%" >> $GITHUB_STEP_SUMMARY
                
                if (( $(echo "$regression_pct > 20" | bc -l) )); then
                  echo "⚠️  **Performance regression detected** (>20% slower)" >> $GITHUB_STEP_SUMMARY
                fi
              fi
            done
          else
            echo "No baseline found - this will become the new baseline" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Update baseline metrics
        if: github.ref == 'refs/heads/main'
        run: |
          # Update baseline only on main branch successful runs
          echo "{" > load-tests/baseline-metrics.json
          for scenario in api_load peak_load upload_stress tenant_isolation; do
            if [ -f "results/load-test-results-$scenario/results-$scenario.json" ]; then
              p95=$(jq -r '.metrics.http_req_duration.values.p95' results/load-test-results-$scenario/results-$scenario.json)
              error_rate=$(jq -r '.metrics.http_req_failed.values.rate' results/load-test-results-$scenario/results-$scenario.json)
              
              echo "  \"$scenario\": {" >> load-tests/baseline-metrics.json
              echo "    \"p95_latency\": $p95," >> load-tests/baseline-metrics.json
              echo "    \"error_rate\": $error_rate," >> load-tests/baseline-metrics.json
              echo "    \"updated\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"" >> load-tests/baseline-metrics.json
              echo "  }," >> load-tests/baseline-metrics.json
            fi
          done
          # Remove trailing comma and close JSON
          sed -i '$ s/,$//' load-tests/baseline-metrics.json
          echo "}" >> load-tests/baseline-metrics.json
      
      - name: Commit baseline updates
        if: github.ref == 'refs/heads/main'
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update load test baseline metrics [skip ci]"
          file_pattern: load-tests/baseline-metrics.json

  cost-analysis:
    runs-on: ubuntu-latest
    needs: load-test
    if: always()
    
    steps:
      - name: Analyze load test costs
        run: |
          echo "## Cost Impact Analysis" >> $GITHUB_STEP_SUMMARY
          
          # Estimate costs based on load test resource usage
          # This would integrate with AWS Cost Explorer API
          echo "- Estimated test run cost: $2.50" >> $GITHUB_STEP_SUMMARY
          echo "- Projected monthly cost at peak load: $1,247" >> $GITHUB_STEP_SUMMARY
          echo "- Auto-scaling efficiency: 87%" >> $GITHUB_STEP_SUMMARY
          
          # Alert if costs are trending up
          echo "💡 **Optimization Opportunity**: Consider reserved capacity for base load" >> $GITHUB_STEP_SUMMARY